% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/RBM.R
\name{RBM}
\alias{RBM}
\title{Restricted Boltzmann Machine}
\usage{
RBM(x, y, n.iter = 100, n.hidden = 30, learning.rate = 0.1,
  plot = FALSE, size.minibatch = 10, momentum = 0.5, lambda = 0.001)
}
\arguments{
\item{x}{A matrix with binary features of shape samples * features.}

\item{y}{A matrix with labels for the data, only when training a classification RBM. (Optional)}

\item{n.iter}{Defines the number of epochs to run contrastive diversion.}

\item{n.hidden}{The number of nodes in the hidden layer.}

\item{learning.rate}{The learning rate, alpha, for training the system.}

\item{plot}{Whether to plot the learning progress of the weights}

\item{size.minibatch}{The size of the minibatches used for training.}

\item{momentum}{Speeds up the gradient descent learning.}

\item{lambda}{The sparsity penalty lambda to prevent the system from overfitting.}
}
\value{
A list with the trained weights of the RBM that can be used for the predict RBM function when supervised learning was applied 
 or the ReconstructRBM function to reconstruct data with the model.
}
\description{
Trains a Restricted Boltzmann Machine on binary data, either supervised 
or unsupervised. This function uses contrastive diversion with k = 1 for training the system.
}
\examples{

# Load the MNIST data
data(MNIST)

# Fit unsupervised RBM with the MNIST data
modelRBM <- RBM(MNIST$trainX, n.iter = 1000, n.hidden = 30, learning.rate = 0.1, 
plot = FALSE, size.minibatch = 10, momentum = 0.5, lambda = 0.001)

# Fit a supervised RBM with the MNIST data
modelRBMSup <- RBM(MNIST$trainX, MNIST$trainY, n.iter = 1000, n.hidden = 30, learning.rate = 0.1, 
plot = FALSE, size.minibatch = 10, momentum = 0.5, lambda = 0.001)

# Add more weight decay when training more parameters
modelRBMSup <- RBM(MNIST$trainX, MNIST$trainY, n.iter = 1000, n.hidden = 100, learning.rate = 0.1, 
plot = FALSE, size.minibatch = 10, momentum = 0.5, lambda = 0.1)


}
